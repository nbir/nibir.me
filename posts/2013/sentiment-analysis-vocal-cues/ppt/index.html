<!DOCTYPE html>

<!--
CSCI-544 NLP Term Project presentation

Copyright (C) 2013, Nibir Bora
Author: Nibir Bora <nbora@usc.edu>
URL: <http://nibir.me>
For license information, see LICENSE
-->


<html lang="en">
	<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=1024" />
    <title>CSCI-544 NLP Term Project presentation - Nibir Bora</title>

		<link href="files/styles.css" rel="stylesheet" />
 	</head>

	<body>
		<div id="impress" class="impress-not-supported">

			<div id="overview" class="step" data-x="0" data-y="1500" data-scale="6"></div>


			<div id="title" class="step titleslide" data-x="0" data-y="0" data-scale="5">
				<p class="large">Sentiment Analysis on Conversational Text:</p>
				<p class="large italics">Do vocal cues play a role?</p>
				<p class="small right"><span class="blue">project #1</span> ~ <span class="red">Nibir Bora</span></p>
			</div>


			<div id="motivation" class="step slide" data-x="-2000" data-y="1000">
				<h1>Motivation...</h1>
				<!--<video class="addborder" width="800" height="450" controls>
					<source src="files/video/SuicidebomberSiri.mp4" type="video/mp4">
				</video>-->
				<div>
					<iframe class="addborder" width="800" height="500" src="http://www.youtube.com/embed/vUQ5DCzH0JI" frameborder="0" allowfullscreen></iframe>
				</div>
			</div>


			<div id="intro-eg" class="step slide" data-x="-2000" data-y="2000">
				<h1>Introduction... example</h1>
				<p class="small">"...dully, slippery slimy stuff... whatever you want to call it."</p>
				<audio controls>
  				<source src="files/sound/slippery-slimy.wav" type="audio/wav">
				</audio>
				<p class="small">"...doing something that you love."</p>
				<audio controls>
  				<source src="files/sound/you-love.wav" type="audio/wav">
				</audio>
				<p class="small">"they love a post office... they, love it.. they're drawn to it."</p>
				<audio controls>
  				<source src="files/sound/love-post-office.wav" type="audio/wav">
				</audio>
			</div>


			<div id="intro-mm" class="step slide" data-x="-2000" data-y="3000">
				<h1>Introduction...</h1>
				<p class="medium center">What is multi-modal?</p>
				<div>
					<img src="files/gfx/multimodal-process.jpg" width="850px"/>
				</div>
				<p class="tiny right">Courtesy: L.P. Morency</p>
			</div>


			<div id="task" class="step slide" data-x="-2000" data-y="4000">
				<h1>The task...</h1>
				<div>
					<img src="files/gfx/task-objective.png" width="850px"/>
				</div>
			</div>


			<div id="data1" class="step slide" data-x="-1000" data-y="1000">
				<h1>Youtube dataset...</h1>
				<p class="tiny">Morency et al. (2011)</p>
				<div>
					<img src="files/gfx/dataset-youtube.jpg" width="850px"/>
				</div>
				<ul class="small">
					<li>47 videos, 30 seconds each</li>
					<li>single person expressing opinions</li>
					<li>utterance level annotations</li>
					<li>positive, neutral, negative classes</li>
					<li>manual transcriptions</li>
				</ul>
			</div>


			<div id="data2" class="step slide" data-x="-1000" data-y="2000">
				<h1>AMI meeting corpus...</h1>
				<p class="tiny">Jean, et al. (2006)</p>
				<div>
					<img src="files/gfx/dataset-ami.jpg" width="850px"/>
				</div>
				<ul class="small">
					<li>100 hours of meeting recordings</li>
					<li>multi-party meeting scenario</li>
					<li>dialog-act level subjectivity annotations <span class="tiny">[Wilson (2008)]</span></li>
					<li>manual transcriptions</li>
				</ul>
				<ul class="small">
					<li>[use only 1 meeting of length ~2hrs]</li>
				</ul>
			</div>


			<div id="features1" class="step slide" data-x="0" data-y="1000">
				<h1>Features...</h1>
				<ul class="small">
					<li><span class="red">Text</span> features:
						<p>- unigrams</p>
						<p>- character n-grams</p>
						<p>- SentiWordNet scores <span class="tiny">[Andrea and Sebastiani (2006)]</span></p>
					</li>
					<li><span class="red">Audio</span> features
						<p>- pitch and intensity based</p>
					</li>
				</ul>
			</div>


			<div id="features2" class="step slide" data-x="0" data-y="2000">
				<h1>Character n-gram features...</h1>
				<p class="tiny">Raaijmakers et al (2008)</p>
				<ul class="small">
					<li>3-gram features for the phrase "<span class="red">natural language</span>":
						<p>#na, nat, atu, tur, ura, ral,</p>
						<p>al#, l#l, #la, lan, ang, ngu,</p>
						<p>gua, uag, age, ge#</p>
					</li>
					<li><span class="red">3-grams</span> and <span class="red">4-grams</span> were used.</li>
				</ul>
				<p class="small"> Character n-grams used in Named Entity Recognition <span class="tiny">[Klein et al. (2003)]</span>, subjective sentence recognition <span class="tiny">[Raaijmakers and Kraaji (2008)]</span>.</p>
			</div>


			<div id="features3" class="step slide" data-x="0" data-y="3000">
				<h1>Audio features...</h1>
				<p class="tiny">Raaijmakers et al (2008), Wrede and Shriberg (2003)</p>
				<ul class="small">
					<li>Pitch (~<span class="red">frequency</span>) based:
						<p>min, max, range, mean,</p>
						<p>standard deviation, mean absolute slope</p>
					</li>
					<li>Intensity (~<span class="red">amplitude</span>) based:
						<p>min, max, range, mean,</p>
						<p>standard deviation, RMS energy</p>
					</li>
				</ul>
				<p class="small">Pitch and intensity were sampled at 100Hz using <span class="red">Praat</span> <span class="tiny">[http://www.fon.hum.uva.nl/praat/]</span></p>
			</div>


			<div id="experiment" class="step slide" data-x="1000" data-y="1000">
				<h1>Experiment...</h1>
				<p class="medium center">...the pipeline.</p>
				<div>
					<img src="files/gfx/exp-svm-pipeline.png" width="850px"/>
				</div>
				<p class="small"><span class="italics">Classifiers</span>: svm, random forests, decision tree</p>
			</div>


			<div id="results1" class="step slide" data-x="1000" data-y="2000">
				<h1>Training results...</h1>
				<div>
					<img class="left" src="files/gfx/bar_Trainingacc.-Youtubeds.png" width="400px"/>
					<img class="left" src="files/gfx/bar_Trainingacc.-AMIcorpus.png" width="400px"/>
				</div>
			</div>

			<div id="results2" class="step slide" data-x="1000" data-y="3000">
				<h1>Test results...</h1>
				<div>
					<img class="left" src="files/gfx/bar_SVM-Youtubeds.png" width="400px"/>
					<img class="left" src="files/gfx/bar_SVM-AMIcorpus.png" width="400px"/>
				</div>
			</div>


			<div id="concl" class="step slide" data-x="2000" data-y="1000">
				<h1>Conclusion...</h1>
				<p class="small">Using a combination of text and vocal features works better for natural text classification.</p>
				<p class="small"></p>
			</div>


			<div id="appli" class="step slide" data-x="2000" data-y="2000">
				<h1>Applications...</h1>
				<ul class="small">
					<li>NL understanding and generation
						<p>- interactive systems: siri</p>
					</li>
					<li>speech analytics
						<p>- call center logs</p>
					</li>
				</ul>
				<div>
					<img class="left" src="files/gfx/logo-nexidia.jpg" height="100px"/>
					<img class="left" src="files/gfx/logo-saygent.png" height="100px"/>
				</div>
				<ul class="small">
					<li>multi-modal:
						<p>- virtual humans</p>
						<p>- psychotherapy</p>
					</li>
				</ul>
			</div>

		</div>

		<script src="files/impress.js"></script>
		<script>impress().init();</script>
	</body>
</html>